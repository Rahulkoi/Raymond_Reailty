<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Raymond Realty - AI Voice Agent</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary: #6366f1;
            --primary-dark: #4f46e5;
            --success: #10b981;
            --danger: #ef4444;
            --warning: #f59e0b;
            --bg-dark: #0f172a;
            --bg-card: #1e293b;
            --bg-input: #334155;
            --text-primary: #f1f5f9;
            --text-secondary: #94a3b8;
        }

        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            font-family: 'Inter', sans-serif;
            background: var(--bg-dark);
            color: var(--text-primary);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
            background-image:
                radial-gradient(at 20% 80%, rgba(99, 102, 241, 0.15) 0, transparent 50%),
                radial-gradient(at 80% 20%, rgba(14, 165, 233, 0.15) 0, transparent 50%);
        }

        .container {
            width: 100%;
            max-width: 500px;
            text-align: center;
        }

        .header {
            margin-bottom: 40px;
        }

        .header h1 {
            font-size: 1.8rem;
            font-weight: 700;
            margin-bottom: 8px;
            background: linear-gradient(135deg, var(--primary), #0ea5e9);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        .header p {
            color: var(--text-secondary);
            font-size: 0.95rem;
        }

        /* Voice Button */
        .voice-container {
            position: relative;
            margin: 40px 0;
        }

        .voice-btn {
            width: 160px;
            height: 160px;
            border-radius: 50%;
            border: none;
            cursor: pointer;
            background: linear-gradient(145deg, var(--bg-card), var(--bg-input));
            box-shadow:
                0 20px 40px rgba(0,0,0,0.3),
                inset 0 -2px 10px rgba(0,0,0,0.2),
                inset 0 2px 10px rgba(255,255,255,0.05);
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.3s ease;
            position: relative;
            overflow: hidden;
        }

        .voice-btn:hover {
            transform: scale(1.05);
        }

        .voice-btn.listening {
            background: linear-gradient(145deg, #dc2626, var(--danger));
            animation: pulse 1.5s infinite;
        }

        .voice-btn.speaking {
            background: linear-gradient(145deg, #059669, var(--success));
        }

        .voice-btn.connecting {
            background: linear-gradient(145deg, #d97706, var(--warning));
        }

        @keyframes pulse {
            0%, 100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.5); }
            50% { box-shadow: 0 0 0 30px rgba(239, 68, 68, 0); }
        }

        .voice-icon {
            font-size: 4rem;
            transition: transform 0.3s;
        }

        .voice-btn:active .voice-icon {
            transform: scale(0.9);
        }

        /* Audio Visualizer */
        .visualizer {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 4px;
            height: 60px;
            margin: 30px 0;
        }

        .bar {
            width: 6px;
            background: var(--primary);
            border-radius: 3px;
            transition: height 0.05s ease;
        }

        .bar.speaking {
            background: var(--success);
        }

        /* Status */
        .status {
            font-size: 1.1rem;
            font-weight: 500;
            margin-bottom: 10px;
            min-height: 30px;
        }

        .status.listening { color: var(--danger); }
        .status.speaking { color: var(--success); }
        .status.connecting { color: var(--warning); }

        /* Transcript */
        .transcript-container {
            background: var(--bg-card);
            border-radius: 16px;
            padding: 20px;
            margin-top: 30px;
            text-align: left;
            max-height: 300px;
            overflow-y: auto;
        }

        .transcript-item {
            margin-bottom: 12px;
            padding-bottom: 12px;
            border-bottom: 1px solid rgba(255,255,255,0.05);
        }

        .transcript-item:last-child {
            border-bottom: none;
            margin-bottom: 0;
            padding-bottom: 0;
        }

        .transcript-item.user {
            color: var(--text-secondary);
        }

        .transcript-item.user::before {
            content: "You: ";
            font-weight: 600;
            color: var(--primary);
        }

        .transcript-item.agent {
            color: var(--text-primary);
        }

        .transcript-item.agent::before {
            content: "Agent: ";
            font-weight: 600;
            color: var(--success);
        }

        /* Instructions */
        .instructions {
            margin-top: 30px;
            padding: 16px;
            background: rgba(99, 102, 241, 0.1);
            border: 1px solid rgba(99, 102, 241, 0.2);
            border-radius: 12px;
            font-size: 0.85rem;
            color: var(--text-secondary);
        }

        .error {
            color: var(--danger);
            margin-top: 20px;
            font-size: 0.9rem;
        }

        /* Latency Display */
        .latency {
            font-size: 0.75rem;
            color: var(--text-secondary);
            margin-top: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Raymond Realty</h1>
            <p>AI Voice Assistant - Powered by ElevenLabs</p>
        </div>

        <div class="voice-container">
            <button class="voice-btn" id="voiceBtn" onclick="toggleVoice()">
                <span class="voice-icon" id="voiceIcon">ðŸŽ¤</span>
            </button>
        </div>

        <div class="visualizer" id="visualizer"></div>

        <div class="status" id="status">Click to start conversation</div>
        <div class="latency" id="latency"></div>

        <div class="transcript-container" id="transcriptContainer" style="display: none;">
            <div id="transcripts"></div>
        </div>

        <div class="instructions">
            <strong>How to use:</strong> Click the microphone and start speaking naturally.
            The AI will respond in real-time. Click again to end the conversation.
        </div>

        <div class="error" id="error"></div>
    </div>

    <script>
        // State
        let ws = null;
        let isActive = false;
        let audioContext = null;
        let mediaStream = null;
        let processor = null;
        let audioQueue = [];
        let isPlaying = false;
        let conversationStartTime = null;

        // DOM
        const voiceBtn = document.getElementById('voiceBtn');
        const voiceIcon = document.getElementById('voiceIcon');
        const status = document.getElementById('status');
        const latency = document.getElementById('latency');
        const transcripts = document.getElementById('transcripts');
        const transcriptContainer = document.getElementById('transcriptContainer');
        const visualizer = document.getElementById('visualizer');
        const error = document.getElementById('error');

        // Create visualizer bars
        for (let i = 0; i < 12; i++) {
            const bar = document.createElement('div');
            bar.className = 'bar';
            bar.style.height = '4px';
            visualizer.appendChild(bar);
        }
        const bars = visualizer.querySelectorAll('.bar');

        // Toggle voice conversation
        async function toggleVoice() {
            if (isActive) {
                stopConversation();
            } else {
                await startConversation();
            }
        }

        // Start conversation with ElevenLabs agent
        async function startConversation() {
            error.textContent = '';
            updateUI('connecting');

            try {
                // Get signed URL from our backend
                const response = await fetch('/elevenlabs/get-signed-url');
                if (!response.ok) {
                    throw new Error('Failed to get connection URL');
                }
                const data = await response.json();

                // Connect to ElevenLabs agent
                ws = new WebSocket(data.signed_url);

                ws.onopen = async () => {
                    console.log('Connected to ElevenLabs agent');
                    isActive = true;
                    conversationStartTime = Date.now();

                    // Start microphone
                    await startMicrophone();
                    updateUI('listening');

                    // Send initial handshake
                    ws.send(JSON.stringify({
                        type: "conversation_initiation_client_data",
                        conversation_config_override: {
                            agent: {
                                prompt: {
                                    prompt: "You are a helpful real estate assistant for Raymond Realty."
                                },
                                first_message: "Hello! I'm your Raymond Realty assistant. How can I help you find your dream home today?"
                            }
                        }
                    }));
                };

                ws.onmessage = (event) => {
                    const data = JSON.parse(event.data);
                    handleAgentMessage(data);
                };

                ws.onerror = (e) => {
                    console.error('WebSocket error:', e);
                    error.textContent = 'Connection error. Please try again.';
                    stopConversation();
                };

                ws.onclose = () => {
                    console.log('Disconnected from agent');
                    if (isActive) {
                        stopConversation();
                    }
                };

            } catch (e) {
                console.error('Failed to start:', e);
                error.textContent = e.message;
                updateUI('idle');
            }
        }

        // Handle messages from ElevenLabs agent
        function handleAgentMessage(data) {
            console.log('Agent message:', data.type, data);

            switch (data.type) {
                case 'user_transcript':
                    // User's speech transcription
                    addTranscript('user', data.user_transcript);
                    break;

                case 'agent_response':
                    // Agent's text response
                    addTranscript('agent', data.agent_response);
                    updateUI('speaking');
                    break;

                case 'audio':
                    // Audio chunk from agent
                    if (data.audio) {
                        queueAudio(data.audio);
                    }
                    break;

                case 'ping':
                    // Respond to keepalive
                    if (data.ping_event && data.ping_event.event_id) {
                        ws.send(JSON.stringify({
                            type: 'pong',
                            event_id: data.ping_event.event_id
                        }));
                    }
                    break;

                case 'interruption':
                    // User interrupted
                    stopPlayback();
                    updateUI('listening');
                    break;

                case 'conversation_initiation_metadata':
                    console.log('Conversation initialized:', data);
                    break;

                case 'internal_tentative_agent_response':
                    // Tentative response (can ignore)
                    break;

                default:
                    console.log('Unhandled message type:', data.type);
            }
        }

        // Start microphone and send audio to agent
        async function startMicrophone() {
            try {
                mediaStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                });

                audioContext = new AudioContext({ sampleRate: 16000 });
                const source = audioContext.createMediaStreamSource(mediaStream);

                // Create analyser for visualizer
                const analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                source.connect(analyser);

                // Process and send audio
                processor = audioContext.createScriptProcessor(2048, 1, 1);
                source.connect(processor);
                processor.connect(audioContext.destination);

                processor.onaudioprocess = (e) => {
                    if (!isActive || !ws || ws.readyState !== WebSocket.OPEN) return;

                    const inputData = e.inputBuffer.getChannelData(0);

                    // Convert to 16-bit PCM
                    const pcm16 = new Int16Array(inputData.length);
                    for (let i = 0; i < inputData.length; i++) {
                        pcm16[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
                    }

                    // Convert to base64
                    const base64 = arrayBufferToBase64(pcm16.buffer);

                    // Send to agent
                    ws.send(JSON.stringify({
                        user_audio_chunk: base64
                    }));

                    // Update visualizer
                    updateVisualizer(analyser);
                };

            } catch (e) {
                console.error('Microphone error:', e);
                error.textContent = 'Microphone access denied. Please allow microphone access.';
                throw e;
            }
        }

        // Queue and play audio from agent
        function queueAudio(base64Audio) {
            const arrayBuffer = base64ToArrayBuffer(base64Audio);
            audioQueue.push(arrayBuffer);

            if (!isPlaying) {
                playNextAudio();
            }
        }

        async function playNextAudio() {
            if (audioQueue.length === 0) {
                isPlaying = false;
                // Back to listening after agent finishes speaking
                if (isActive) {
                    updateUI('listening');
                }
                return;
            }

            isPlaying = true;
            const arrayBuffer = audioQueue.shift();

            try {
                // Create audio context for playback if needed
                if (!audioContext || audioContext.state === 'closed') {
                    audioContext = new AudioContext({ sampleRate: 16000 });
                }

                // Decode and play
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer.slice(0));
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);

                source.onended = () => {
                    playNextAudio();
                };

                source.start();
            } catch (e) {
                console.error('Audio playback error:', e);
                playNextAudio();
            }
        }

        function stopPlayback() {
            audioQueue = [];
            isPlaying = false;
        }

        // Stop conversation
        function stopConversation() {
            isActive = false;

            if (processor) {
                processor.disconnect();
                processor = null;
            }

            if (mediaStream) {
                mediaStream.getTracks().forEach(t => t.stop());
                mediaStream = null;
            }

            if (ws) {
                ws.close();
                ws = null;
            }

            stopPlayback();
            updateUI('idle');

            if (conversationStartTime) {
                const duration = ((Date.now() - conversationStartTime) / 1000).toFixed(1);
                latency.textContent = `Conversation lasted ${duration}s`;
            }
        }

        // Update UI state
        function updateUI(state) {
            voiceBtn.className = 'voice-btn ' + state;

            switch (state) {
                case 'idle':
                    voiceIcon.textContent = 'ðŸŽ¤';
                    status.textContent = 'Click to start conversation';
                    status.className = 'status';
                    bars.forEach(bar => {
                        bar.className = 'bar';
                        bar.style.height = '4px';
                    });
                    break;

                case 'connecting':
                    voiceIcon.textContent = 'â³';
                    status.textContent = 'Connecting...';
                    status.className = 'status connecting';
                    break;

                case 'listening':
                    voiceIcon.textContent = 'ðŸ”´';
                    status.textContent = 'Listening... Speak now';
                    status.className = 'status listening';
                    bars.forEach(bar => bar.className = 'bar');
                    break;

                case 'speaking':
                    voiceIcon.textContent = 'ðŸ”Š';
                    status.textContent = 'Agent speaking...';
                    status.className = 'status speaking';
                    bars.forEach(bar => bar.className = 'bar speaking');
                    break;
            }
        }

        // Update audio visualizer
        function updateVisualizer(analyser) {
            const data = new Uint8Array(analyser.frequencyBinCount);
            analyser.getByteFrequencyData(data);

            const step = Math.floor(data.length / bars.length);
            bars.forEach((bar, i) => {
                const value = data[i * step];
                const height = Math.max(4, (value / 255) * 50);
                bar.style.height = height + 'px';
            });
        }

        // Add transcript to UI
        function addTranscript(role, text) {
            if (!text) return;

            transcriptContainer.style.display = 'block';

            const item = document.createElement('div');
            item.className = 'transcript-item ' + role;
            item.textContent = text;
            transcripts.appendChild(item);

            // Scroll to bottom
            transcriptContainer.scrollTop = transcriptContainer.scrollHeight;
        }

        // Utility functions
        function arrayBufferToBase64(buffer) {
            const bytes = new Uint8Array(buffer);
            let binary = '';
            for (let i = 0; i < bytes.length; i++) {
                binary += String.fromCharCode(bytes[i]);
            }
            return btoa(binary);
        }

        function base64ToArrayBuffer(base64) {
            const binary = atob(base64);
            const bytes = new Uint8Array(binary.length);
            for (let i = 0; i < binary.length; i++) {
                bytes[i] = binary.charCodeAt(i);
            }
            return bytes.buffer;
        }

        // Cleanup on page unload
        window.onbeforeunload = () => {
            stopConversation();
        };
    </script>
</body>
</html>

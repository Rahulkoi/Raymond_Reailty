<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Raymond Realty - Voice Assistant</title>
    <style>
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: #eee;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }
        .header {
            background: rgba(0,0,0,0.3);
            padding: 15px 20px;
            text-align: center;
        }
        .header h1 { font-size: 1.5rem; color: #00d4ff; }
        .main-container {
            flex: 1;
            display: flex;
            flex-direction: column;
            max-width: 800px;
            margin: 0 auto;
            width: 100%;
            padding: 20px;
        }
        .conversation {
            flex: 1;
            overflow-y: auto;
            padding: 10px 0;
            margin-bottom: 20px;
        }
        .message { margin: 12px 0; display: flex; flex-direction: column; }
        .message.user { align-items: flex-end; }
        .message.assistant { align-items: flex-start; }
        .message .bubble {
            max-width: 80%;
            padding: 12px 16px;
            border-radius: 18px;
            line-height: 1.4;
        }
        .message.user .bubble { background: #0066cc; border-bottom-right-radius: 4px; }
        .message.assistant .bubble { background: #2d3748; border-bottom-left-radius: 4px; }
        .message .label { font-size: 11px; opacity: 0.6; margin-bottom: 4px; padding: 0 8px; }

        .property-cards { display: flex; flex-direction: column; gap: 12px; margin-top: 15px; }
        .property-card {
            background: linear-gradient(145deg, #2d3748 0%, #1a202c 100%);
            border-radius: 12px;
            padding: 15px;
            border: 1px solid rgba(255,255,255,0.1);
        }
        .property-card h3 { color: #00d4ff; font-size: 1rem; margin-bottom: 8px; }
        .property-card .price { font-size: 1.1rem; font-weight: bold; color: #48bb78; margin-bottom: 8px; }
        .property-card .details { font-size: 0.85rem; opacity: 0.9; margin-bottom: 10px; }
        .property-card .amenities { font-size: 0.8rem; opacity: 0.7; margin-bottom: 12px; }
        .property-card .links { display: flex; flex-wrap: wrap; gap: 8px; }
        .property-card .links a {
            background: rgba(0,212,255,0.2);
            color: #00d4ff;
            padding: 6px 12px;
            border-radius: 6px;
            text-decoration: none;
            font-size: 0.8rem;
        }
        .property-card .links a:hover { background: rgba(0,212,255,0.4); }

        .voice-control {
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
            background: rgba(0,0,0,0.2);
            border-radius: 20px;
        }
        .status-text { font-size: 1rem; margin-bottom: 15px; font-weight: 500; }
        .status-text.listening { color: #f56565; }
        .status-text.processing { color: #ecc94b; }
        .status-text.speaking { color: #48bb78; }

        .mic-button {
            width: 100px;
            height: 100px;
            border-radius: 50%;
            border: none;
            cursor: pointer;
            font-size: 2.5rem;
            transition: all 0.3s;
        }
        .mic-button.inactive { background: linear-gradient(145deg, #4a5568, #2d3748); }
        .mic-button.listening {
            background: linear-gradient(145deg, #fc8181, #f56565);
            animation: pulse 1s infinite;
            box-shadow: 0 0 40px rgba(245, 101, 101, 0.6);
        }
        .mic-button.processing { background: linear-gradient(145deg, #f6e05e, #ecc94b); }
        .mic-button.speaking { background: linear-gradient(145deg, #68d391, #48bb78); }
        @keyframes pulse { 0%, 100% { transform: scale(1); } 50% { transform: scale(1.08); } }

        .audio-level {
            width: 250px;
            height: 6px;
            background: rgba(255,255,255,0.1);
            border-radius: 3px;
            margin-top: 20px;
            overflow: hidden;
        }
        .audio-level-bar { height: 100%; background: #00d4ff; width: 0%; transition: width 0.05s; }
        .hint { font-size: 0.8rem; opacity: 0.6; margin-top: 15px; }
    </style>
</head>
<body>
    <div class="header">
        <h1>Raymond Realty - AI Voice Assistant</h1>
    </div>

    <div class="main-container">
        <div class="conversation" id="conversation">
            <div class="message assistant">
                <div class="label">Priya</div>
                <div class="bubble">Hi! I'm Priya from Raymond Realty. Click the button below to start our conversation. Just speak naturally - I'll understand when you're done!</div>
            </div>
        </div>

        <div class="voice-control">
            <div class="status-text" id="status">Click to Start Conversation</div>
            <button class="mic-button inactive" id="micButton" onclick="handleMicClick()">ðŸŽ¤</button>
            <div class="audio-level"><div class="audio-level-bar" id="audioLevel"></div></div>
            <div class="hint" id="hint">One click to start - then just talk naturally. Say "bye" or "end conversation" when done.</div>
        </div>
    </div>

    <script>
        let ws = null;
        let isActive = false;
        let isListening = false;
        let isProcessing = false;
        let isSpeaking = false;

        let audioContext, analyser, microphone, processor, stream;
        let audioChunks = [];
        let conversationEnded = false;

        // VAD settings
        const SILENCE_THRESHOLD = 0.015;
        const SILENCE_DURATION = 1800; // 1.8 seconds
        const SPEECH_MIN_DURATION = 500; // Must speak at least 0.5s
        let silenceTimer = null;
        let hasSpeechStarted = false;
        let speechStartTime = null;

        const statusEl = document.getElementById('status');
        const micButton = document.getElementById('micButton');
        const audioLevelEl = document.getElementById('audioLevel');
        const hintEl = document.getElementById('hint');
        const conversationEl = document.getElementById('conversation');

        function setStatus(state, text) {
            statusEl.textContent = text;
            statusEl.className = 'status-text ' + state;
            micButton.className = 'mic-button ' + state;
        }

        function addMessage(role, text) {
            const msg = document.createElement('div');
            msg.className = 'message ' + role;
            msg.innerHTML = `<div class="label">${role === 'user' ? 'You' : 'Priya'}</div><div class="bubble">${text}</div>`;
            conversationEl.appendChild(msg);
            conversationEl.scrollTop = conversationEl.scrollHeight;
        }

        function addPropertyCards(properties) {
            if (!properties?.length) return;
            const container = document.createElement('div');
            container.className = 'message assistant';
            let html = '<div class="label">Recommended Properties</div><div class="property-cards">';
            for (const p of properties) {
                html += `<div class="property-card">
                    <h3>${p.name}</h3>
                    <div class="price">â‚¹ ${p.price}</div>
                    <div class="details">${p.bhk} ${p.type} in ${p.location}<br>${p.area_sqft} sq.ft | ${p.possession}</div>
                    <div class="amenities">${p.amenities?.join(' â€¢ ') || ''}</div>
                    <div class="links">
                        ${p.property_url ? `<a href="${p.property_url}" target="_blank">View Details</a>` : ''}
                        ${p.virtual_tour_url ? `<a href="${p.virtual_tour_url}" target="_blank">Virtual Tour</a>` : ''}
                        ${p.brochure_url ? `<a href="${p.brochure_url}" target="_blank">Brochure</a>` : ''}
                        ${p.contact_number ? `<a href="tel:${p.contact_number}">Call</a>` : ''}
                    </div>
                </div>`;
            }
            html += '</div>';
            container.innerHTML = html;
            conversationEl.appendChild(container);
            conversationEl.scrollTop = conversationEl.scrollHeight;
        }

        function handleMicClick() {
            if (!isActive) {
                startConversation();
            } else if (isListening) {
                // Manual end if needed
                endTurn();
            }
        }

        async function startConversation() {
            conversationEnded = false;
            ws = new WebSocket(`ws://${window.location.host}/ws/voice`);

            ws.onopen = () => {
                isActive = true;
                hintEl.textContent = 'Speak naturally - say "bye" when done';
                startListening();
            };

            ws.onclose = () => {
                isActive = false;
                stopListening();
                setStatus('inactive', 'Click to Start New Conversation');
            };

            ws.onmessage = async (e) => {
                if (e.data instanceof Blob) {
                    audioChunks.push(e.data);
                } else {
                    const data = JSON.parse(e.data);
                    if (data.type === 'transcript') addMessage('user', data.text);
                    else if (data.type === 'response') addMessage('assistant', data.text);
                    else if (data.type === 'properties') addPropertyCards(data.data);
                    else if (data.type === 'audio_end') playResponse();
                    else if (data.type === 'conversation_ended') {
                        conversationEnded = true;
                    }
                    else if (data.type === 'error') {
                        setStatus('listening', 'Listening...');
                        isProcessing = false;
                        startListening();
                    }
                }
            };
        }

        async function startListening() {
            if (isListening) return;

            try {
                stream = await navigator.mediaDevices.getUserMedia({
                    audio: { sampleRate: 16000, channelCount: 1, echoCancellation: true, noiseSuppression: true }
                });

                audioContext = new AudioContext({ sampleRate: 16000 });
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 512;

                microphone = audioContext.createMediaStreamSource(stream);
                microphone.connect(analyser);

                processor = audioContext.createScriptProcessor(4096, 1, 1);
                processor.onaudioprocess = (e) => {
                    if (isListening && ws?.readyState === WebSocket.OPEN) {
                        ws.send(new Float32Array(e.inputBuffer.getChannelData(0)).buffer);
                    }
                };
                microphone.connect(processor);
                processor.connect(audioContext.destination);

                isListening = true;
                hasSpeechStarted = false;
                speechStartTime = null;
                setStatus('listening', 'Listening... Speak now!');

                monitorAudio();
            } catch (err) {
                console.error('Mic error:', err);
                setStatus('inactive', 'Microphone blocked');
            }
        }

        function monitorAudio() {
            if (!isListening) return;

            const data = new Uint8Array(analyser.frequencyBinCount);
            analyser.getByteFrequencyData(data);

            const level = data.reduce((a, b) => a + b, 0) / data.length / 255;
            audioLevelEl.style.width = Math.min(100, level * 500) + '%';

            if (level > SILENCE_THRESHOLD) {
                // Speech detected
                if (!hasSpeechStarted) {
                    hasSpeechStarted = true;
                    speechStartTime = Date.now();
                    setStatus('listening', 'Listening...');
                }
                // Clear silence timer
                if (silenceTimer) {
                    clearTimeout(silenceTimer);
                    silenceTimer = null;
                }
            } else if (hasSpeechStarted) {
                // Silence after speech
                const speechDuration = Date.now() - speechStartTime;

                if (speechDuration > SPEECH_MIN_DURATION && !silenceTimer) {
                    setStatus('listening', 'Continue or wait...');
                    silenceTimer = setTimeout(() => {
                        if (isListening && hasSpeechStarted) {
                            endTurn();
                        }
                    }, SILENCE_DURATION);
                }
            }

            if (isListening) requestAnimationFrame(monitorAudio);
        }

        function stopListening() {
            isListening = false;
            if (silenceTimer) { clearTimeout(silenceTimer); silenceTimer = null; }
            if (processor) processor.disconnect();
            if (microphone) microphone.disconnect();
            if (audioContext) audioContext.close();
            if (stream) stream.getTracks().forEach(t => t.stop());
            audioLevelEl.style.width = '0%';
        }

        function endTurn() {
            if (!isListening) return;
            stopListening();
            isProcessing = true;
            setStatus('processing', 'Processing...');
            if (ws?.readyState === WebSocket.OPEN) ws.send('END');
        }

        async function playResponse() {
            if (!audioChunks.length) {
                isProcessing = false;
                startListening();
                return;
            }

            isSpeaking = true;
            isProcessing = false;
            setStatus('speaking', 'Speaking...');

            const blob = new Blob(audioChunks, { type: 'audio/mpeg' });
            audioChunks = [];
            const audio = new Audio(URL.createObjectURL(blob));

            audio.onended = () => {
                isSpeaking = false;
                // Check if conversation ended
                if (conversationEnded) {
                    if (ws) ws.close();
                    setStatus('inactive', 'Conversation Ended - Click to Start New');
                    conversationEnded = false;
                    return;
                }
                // Auto-continue listening
                if (isActive) setTimeout(startListening, 300);
            };

            audio.onerror = () => {
                isSpeaking = false;
                if (isActive) startListening();
            };

            await audio.play();
        }

        window.onbeforeunload = () => { if (ws) ws.close(); stopListening(); };
    </script>
</body>
</html>
